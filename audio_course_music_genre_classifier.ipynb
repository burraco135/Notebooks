{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN4rNVGsA7ztt3f7XuqQxCz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/burraco135/Notebooks/blob/master/audio_course_music_genre_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build a music genre classifier (Unit 4)\n",
        "\n",
        "## Goal\n",
        "Achieve 87% accuracy on this dataset"
      ],
      "metadata": {
        "id": "3cy4HASQJuD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q datasets gradio transformers numpy huggingface_hub evaluate\n",
        "%pip install -q -U accelerate"
      ],
      "metadata": {
        "id": "rkT7zc0pKQ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load gtzan dataset\n",
        "gtzan = load_dataset(\"marsyas/gtzan\", \"all\")\n",
        "gtzan"
      ],
      "metadata": {
        "id": "G2ulg_YIJ0KF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create validation set from the dataset\n",
        "gtzan = gtzan[\"train\"].train_test_split(seed=42, shuffle=True, test_size=0.1)\n",
        "gtzan"
      ],
      "metadata": {
        "id": "EgGisQxtKqol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# audio files are represented as 1-dimensional arrays\n",
        "#   the value of the array represents the amplitude at that timestep\n",
        "# the sampling rate is 22,050 Hz\n",
        "#   there are 22,050 amplitude valllues sampled per second\n",
        "gtzan[\"train\"][0]"
      ],
      "metadata": {
        "id": "lF4N1E0qK57G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# int2str can map the genre feature (int) to human-readable names (str)\n",
        "id2label_fn = gtzan[\"train\"].features[\"genre\"].int2str\n",
        "print(\"Genre: \", id2label_fn(gtzan[\"train\"][0][\"genre\"]))"
      ],
      "metadata": {
        "id": "cMmj2o7RLau3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listen 4 random audio files from train with their labels\n",
        "import gradio as gr\n",
        "\n",
        "def generate_audio():\n",
        "  example = gtzan[\"train\"].shuffle()[0]\n",
        "  audio = example[\"audio\"]\n",
        "  return (\n",
        "      audio[\"sampling_rate\"],\n",
        "      audio[\"array\"]\n",
        "  ), id2label_fn(example[\"genre\"])\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Column():\n",
        "    for _ in range(4):\n",
        "      audio, label = generate_audio()\n",
        "      output = gr.Audio(audio, label=label)\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "KiNckLJ8L3SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transformers proves a class that can automatically select the correct feature\n",
        "from transformers import AutoFeatureExtractor\n",
        "\n",
        "model_id = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\n",
        "    model_id, do_normalize=True, return_attention_mask=False\n",
        ")"
      ],
      "metadata": {
        "id": "iy8qlcOlNAUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature extractor sampling rate is 16,000\n",
        "sampling_rate = feature_extractor.sampling_rate\n",
        "print(\"Feature extractor sampling rate:\", sampling_rate)"
      ],
      "metadata": {
        "id": "31LKJ-DgNifw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resampling all audio file for feature extractor\n",
        "from datasets import Audio\n",
        "\n",
        "gtzan = gtzan.cast_column(\"audio\", Audio(sampling_rate=sampling_rate))\n",
        "gtzan[\"train\"][0]"
      ],
      "metadata": {
        "id": "qmPoW2n0OFO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rescaling each sample to zero mean and unit variance\n",
        "import numpy as np\n",
        "\n",
        "sample = gtzan[\"train\"][0][\"audio\"]\n",
        "print(f\"Mean: {np.mean(sample['array']):.3}, Variance: {np.var(sample['array']):.3}\")\n",
        "\n",
        "inputs = feature_extractor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"])\n",
        "\n",
        "print(f\"inputs keys: {list(inputs.keys())}\")\n",
        "\n",
        "print(\n",
        "    f\"Mean: {np.mean(inputs['input_values']):.3}, Variance: {np.var(inputs['input_values']):.3}\"\n",
        ")"
      ],
      "metadata": {
        "id": "OSUOk1_kOrQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# truncate audio longer than 30s\n",
        "max_duration = 30.0\n",
        "\n",
        "def preprocess_function(examples):\n",
        "  audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
        "  inputs = feature_extractor(\n",
        "      audio_arrays,\n",
        "      sampling_rate=feature_extractor.sampling_rate,\n",
        "      max_length=int(feature_extractor.sampling_rate * max_duration),\n",
        "      truncation=True,\n",
        "      return_attention_mask=True\n",
        "  )\n",
        "  return inputs\n",
        "\n",
        "gtzan_encoded = gtzan.map(\n",
        "    preprocess_function, remove_columns=[\"audio\", \"file\"], batched=True, num_proc=1\n",
        ")"
      ],
      "metadata": {
        "id": "6KRUKpPdP5JP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rename genre column to label\n",
        "gtzan_encoded = gtzan_encoded.rename_column(\"genre\", \"label\")"
      ],
      "metadata": {
        "id": "vOCxF7cWRXxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# obtain label mappings from dataset\n",
        "id2label = {\n",
        "    str(i): id2label_fn(i)\n",
        "    for i in range(len(gtzan_encoded[\"train\"].features[\"label\"].names))\n",
        "}\n",
        "\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "\n",
        "print(\"Genre: \", id2label[\"7\"])"
      ],
      "metadata": {
        "id": "4hF6Hw3EQr2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine-tuning a model\n",
        "from transformers import AutoModelForAudioClassification\n",
        "\n",
        "num_labels = len(id2label)\n",
        "\n",
        "model = AutoModelForAudioClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=num_labels,\n",
        "    label2id=label2id,\n",
        "    id2label=id2label,\n",
        "    ignore_mismatched_sizes=True\n",
        ")"
      ],
      "metadata": {
        "id": "VAoF7546RfzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# linking the notebook to Hub\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "9_VsBbDcR1wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training arguments\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "model_name = model_id.split(\"/\")[-1]\n",
        "batch_size = 4\n",
        "gradient_accumulation_steps = 4\n",
        "num_train_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    f\"{model_name}-finetuned-gtzan\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_train_epochs,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    fp16=True,\n",
        "    push_to_hub=False\n",
        ")"
      ],
      "metadata": {
        "id": "FApZXczhSXC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the metrics\n",
        "import evaluate\n",
        "\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "  \"\"\"Computes accuracy on a batch of predictions\"\"\"\n",
        "  predictions = np.argmax(eval_pred.predictions, axis=1)\n",
        "  return metric.compute(predictions=predictions, references=eval_pred.label_ids)"
      ],
      "metadata": {
        "id": "iYVt3hsKTWtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=gtzan_encoded[\"train\"],\n",
        "    eval_dataset=gtzan_encoded[\"test\"],\n",
        "    tokenizer=feature_extractor,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "IiTH1nN4VCtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import whoami\n",
        "\n",
        "whoami()"
      ],
      "metadata": {
        "id": "kpfdxdV6iMSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# push the model on the hub\n",
        "kwargs = {\n",
        "    \"dataset_tags\": \"marsyas/gtzan\",\n",
        "    \"dataset\": \"GTZAN\",\n",
        "    \"model_name\": f\"{model_name}-finetuned-gtzan\",\n",
        "    \"finetuned_from\": model_id,\n",
        "    \"tasks\": \"audio-classification\",\n",
        "}\n",
        "\n",
        "trainer.push_to_hub(**kwargs)"
      ],
      "metadata": {
        "id": "RCqDVJrnWC2Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}